{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "# Just to test at the very begining\n",
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import IPythonMagic\n",
    "from Timer import Timer\n",
    "import matplotlib as plt\n",
    "import pycuda.driver as cuda_driver\n",
    "import pycuda.compiler as cuda_compiler\n",
    "from pycuda.gpuarray import GPUArray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python version 3.6.6 (default, Sep 12 2018, 18:26:19) \n",
      "[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\n"
     ]
    }
   ],
   "source": [
    "%setup_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registering context in user workspace\n",
      "Creating context\n",
      "PyCUDA version 2018.1.1\n",
      "CUDA version (9, 1, 0)\n",
      "Driver version 10000\n",
      "Using 'Tesla K80' GPU\n",
      " => compute capability: (3, 7)\n",
      " => memory: 11002 / 11441 MB available\n",
      "Created context handle <43141776>\n",
      "Using CUDA cache dir /home/ubuntu/jupyter_notebooks/Thomas_Bellotti/MilanoGPU2018/notebooks/cuda_cache\n"
     ]
    }
   ],
   "source": [
    "%cuda_context_handler context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: The CUDA compiler succeeded, but said the following:\n",
      "kernel.cu(9): warning: variable \"gid\" was declared but never referenced\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kernel_src = \"\"\"\n",
    "\n",
    "__global__ void shmemReduction(float * output, float * input, int size){\n",
    "\n",
    "    // First we stride through global memory and compute the \n",
    "    // maximum for every thread\n",
    "    \n",
    "    int gid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    float max_value = -999999.99; // FIx me ..\n",
    "    \n",
    "    // threadIdx.x is always zero since we use one block.\n",
    "    for (int i = threadIdx.x; i < size; i = i + blockDim.x){\n",
    "        max_value = fmaxf(max_value, input[i]); \n",
    "    }\n",
    "    \n",
    "    // Temporary ouutput to check\n",
    "    \n",
    "    output[threadIdx.x] = max_value; \n",
    "    \n",
    "    \n",
    "    // Store the pair thread maximum in shared memory\n",
    "    \n",
    "    __shared__ float max_shared[32];\n",
    "    max_shared[threadIdx.x] = max_value;\n",
    "    \n",
    "    // Synchronize in order all the thread to see the same shared memory\n",
    "    \n",
    "    __syncthreads();\n",
    "    \n",
    "    // Find max in shared memory\n",
    "    // Reduce from 32 to 16 elements\n",
    "    if (threadIdx.x < 16){\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x], max_shared[threadIdx.x + 16]);\n",
    "    }\n",
    "     // Reduce from 16 to 8 elements\n",
    "    if (threadIdx.x < 8){\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x], max_shared[threadIdx.x + 8]);\n",
    "    }\n",
    "    // Reduce from 8 to 4 elements\n",
    "    if (threadIdx.x < 4){\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x], max_shared[threadIdx.x + 4]);\n",
    "    }\n",
    "    // Reduce from 4 to 2 elements\n",
    "    if (threadIdx.x < 2){\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x], max_shared[threadIdx.x + 2]);\n",
    "    }\n",
    "    // Reduce from 2 to 1 elements\n",
    "    if (threadIdx.x < 1){\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x], max_shared[threadIdx.x + 1]);\n",
    "    }\n",
    "    \n",
    "    // Write out to output\n",
    "    \n",
    "    if (threadIdx.x == 0)\n",
    "        output[0] = max_shared[0];\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "kernel_module = cuda_compiler.SourceModule (kernel_src)\n",
    "kernel_function = kernel_module.get_function(\"shmemReduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 64\n",
    "a = np.random.random((1,n)).astype(np.float32)\n",
    "\n",
    "\n",
    "a_g = GPUArray(a.shape, a.dtype)\n",
    "a_g.set(a)\n",
    "\n",
    "num_threads = 32\n",
    "b = np.empty((11,num_threads)).astype(np.float32)\n",
    "\n",
    "b_g = GPUArray (b.shape, b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9863307  0.45503062 0.8536101  0.72530013 0.8314264  0.5278172\n",
      " 0.48564497 0.96148294 0.4121069  0.5963757  0.7839482  0.91644627\n",
      " 0.27043173 0.70218146 0.48154196 0.63125986 0.75924814 0.5139514\n",
      " 0.44183996 0.3956442  0.9863307  0.45015293 0.5160185  0.3158753\n",
      " 0.9843556  0.60835934 0.74241364 0.52127564 0.84744126 0.75101244\n",
      " 0.50365454 0.74133193]\n",
      "0.9863307\n"
     ]
    }
   ],
   "source": [
    "block_size = (num_threads, 1, 1)\n",
    "grid_size = (1,1,1)\n",
    "\n",
    "kernel_function(b_g, a_g, np.int32(n), grid = grid_size, block = block_size)\n",
    "\n",
    "b_g.get(b)\n",
    "\n",
    "print(b[0])\n",
    "\n",
    "print(np.max(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
